---
title: "Tidyverse Problem Set"
author: "MA615"
date: "September 29, 2019"
output: pdf_document
urlcolor: blue
---

```{r setup, include=FALSE}
library(knitr)
  options(tinytex.verbose = TRUE)
  opts_chunk$set(echo = TRUE)
library(tidyverse)
library(kableExtra)
```

The purpose of this problem set is to provide data contexts in which to exercise the capabilitiues of the tidyverse. While some questons require specific answers, other parts of the problems have been written to be purposely ambiguous, requiring you to think through the presentation details of your answer. 




HOLD THE PRESSES!  
As I was preparing to post these problems yesterday, I noticed that tidyr had been updata in the last few weeks. I was looking for more exercises on gather() and spread() -- which are always difficult to master.  And I found that they have been superceded!!  Why do I love working with R as the tidyversie is on a path of continuous improvement? Because the improvements come from developers who write things like this:


_For some time, it’s been obvious that there is something fundamentally wrong with the design of spread() and gather(). Many people don’t find the names intuitive and find it hard to remember which direction corresponds to spreading and which to gathering. It also seems surprisingly hard to remember the arguments to these functions, meaning that many people (including me!) have to consult the documentation every time._  [Hadley Wickham, Pivot Vingette](https://cran.r-project.org/web/packages/tidyr/vignettes/pivot.html)


So... before you do anymore tidyverse exercises,
Read this [tidyr 1.0.0](https://www.tidyverse.org/articles/2019/09/tidyr-1-0-0/).

Then go to the [tidyr cran page](https://cran.r-project.org/web/packages/tidyr/index.html) 
and to the examples and exercies in the new vignettes.

In your solutions to the problems below, if you need to use table reshaping functions from TidyR, be sure that you use pivot_longer(), and pivot_wider().



### Problem 1

1.1 Load the gapminder data from the gapminder package.
```{r}
library(gapminder)
data(gapminder)
```

1.2 How many continents are included in the data set?
```{r}
continents_num <- length(unique(gapminder$continent))
paste("Total",continents_num,"continents are included")
```

1.3 How many countrys are included?  How many countries per continent?
```{r}
## count num of countries
country_num <- length(unique(gapminder$country))
paste("Total",country_num,"countries are included")
## summarize num of counries in each countinent
kable(gapminder %>% group_by(continent) %>% summarize(num_countries = n_distinct(country)),align ="c",booktabs=TRUE) %>%
kable_styling(latex_options = 'hold_position',font_size = 12,full_width = F,position = "center")
paste("Africa : 52, Americas: 25, Asia:33, Oceania: 2")
```

1.4 Using the gapminder data, produce a report showing the continents in the dataset, total population per continent, and GDP per capita.  Be sure that the table is properly labeled and suitable for inclusion in a printed report.
```{r}
report <- gapminder %>% group_by(continent)%>% summarize(TTL_Avg_pop = sum(as.numeric(pop))/length(unique(year)), TTL_gdpPercap = sum(gdpPercap*as.numeric(pop))/sum(as.numeric(pop)))

kable(report,digits = 2,booktabs=TRUE,align = 'c') %>% 
  kable_styling(latex_options = 'hold_position',font_size = 12,full_width = F)

```

1.5 Produce a well-labeled table that summarizes GDP per capita for the countries in each continent,  contrasting the years 1952 and 2007.
```{r}
df1 <- gapminder %>% select(continent,country,year,gdpPercap) %>% filter (year %in% c(1952,2007)) %>% spread(year,gdpPercap)
colnames(df1) <- c("continent","country","year_1952","year_2007")
df1 <- df1 %>% arrange(continent,desc(year_2007))
kable(df1,digits =2,booktabs=TRUE,caption="GDP per capita for the countries of each continent in year 1952 vs  2007",align = "c")%>% 
  kable_styling(latex_options = 'hold_position',font_size =12,full_width = F)
#kable(df1,digits =2,booktabs=TRUE,caption="GDP per capita for the countries of each continent in year 1952 vs  2007",col.names = c("Class", "City", "Highway"),align = "c")%>% 
#kable_styling(latex_options = 'hold_position',font_size =12,full_width = F)
```

1.6 Product a plot that summarizes the same data as the table. There should be two plots per continent.
```{r}
gapminder %>%
  filter(year %in% c(1952, 2007)) %>% group_by(continent,year)%>% summarize(gdpPercap = sum(gdpPercap*as.numeric(pop))/sum(as.numeric(pop))) %>%
  ggplot()+
  geom_bar(mapping=aes(x=as.factor(year),y=gdpPercap),stat="identity") +
  facet_grid(.~continent)
```

1.7 Which countries in the dataset have had periods of negative population growth?
Illustrate your answer with a table or plot.
```{r}
df2 <- gapminder %>% select(continent,country,year,pop) %>% filter (year %in% c(1952,2007)) %>% spread(year,pop)
colnames(df2) <- c("continent","country","year_1952","year_2007")
filter (df2,year_2007<year_1952)
```

1.8 Which countries in the dataset have had the highest rate of growth in per capita GDP?
Illustrate your answer with a table or plot.
```{r}
df3 <- df1 %>% mutate(growth_rate = (year_2007-year_1952)/year_1952) %>% arrange(desc(growth_rate))
head(df3,1)


```

\newpage

### Problem 2

The data for Problem 2 is the Fertility data in the AER package.  This data is from the 1980 US Census and is comprised of date on married women aged 21-35 with two or more children.  The data report the gender of each woman's first and second child, the woman's race, age, number of weeks worked in 1979, and whether the woman had more than two children.
```{r}
library(AER)
data(Fertility)
```


There are four possible gender combinations for the first two Children.  Product a plot the contracts the frequency of these four combinations. Are the frequencies different for women in their 20s and wemen who are older than 29?
```{r}
Fertility <- as_tibble(Fertility)
gender_comb <- Fertility %>% mutate(gender_comb = ifelse(gender1 == "male" & gender2 == "male", "MM", ifelse(gender1 == "male" & gender2 == "female","MF",ifelse(gender1 == "female" & gender2 == "male","FM","FF"))))

gender_comb %>%
    ggplot()+ geom_bar(mapping=aes(x=gender_comb,fill=age >29),stat="count")

```

Produce a plot that contrasts the frequency of having more than two children by race and ethnicity.  
```{r}
f_race_only_three <- Fertility %>% gather(`afam`,`hispanic`,`other`, key = ethnicity, value = yes )%>%
  filter(yes == "yes")
ggplot(data = f_race_only_three)+
  geom_bar(mapping =aes(x=ethnicity,fill = morekids))

```


### Problem 3

Use the mtcars and mpg datasets.  
```{r}
data(mpg)
data(mtcars)
```

How many times does the letter "e" occur in mtcars rownames?
```{r}
mtc <- as_tibble(rownames_to_column(mtcars, var = "Model"))
mtc$number.of.e <- str_count(mtc$Model, "e")
sum(mtc$number.of.e)

```

How many cars in mtcars have the brand Merc?
```{r}
sum(str_count(mtc$Model,"Merc"))
```

How many cars in mpg have the brand("manufacturer" in mpg) Merc?
```{r}
sum(str_count(mpg$manufacturer,"mercury"))

```

Contrast the mileage data for Merc cars as reported in mtcars and mpg.  Use tables, plots, and a short explaination.


### Problem 4

Install the babynames package.
```{r}
library(babynames)
data(babynames)
babyn <- as_tibble(babynames)
```

Draw a sample of 500,000 rows from the babynames data
```{r}
s <- sample(x = 1:nrow(babynames), size = 500000, replace = FALSE)
sample_babynames <- babynames[s,]
head(sample_babynames,10)

```

Produce a tabble that displays the five most popular boy names and girl names
in the years 1880,1920, 1960, 2000.
```{r}

```


What names overlap boys and girls?
```{r}
boys <- babyn %>% filter(sex == "M")
girls <- babyn %>% filter(sex == "F")
overlap <- intersect(boys$name,girls$name)

```

What names were used in the 19th century but have not been used in the 21sth century?
```{r}
nineteenth <- babyn %>% filter(year >= 1800 & year <= 1899)
twentyth <- babyn %>% filter(year >= 2000 & year <= 2017)
#count(!(twentyth$name %in% nineteenth))

```

Produce a chart that shows the relative frequency of the names "Donald", "Hilary", "Hillary", "Joe", "Barrack",  over the years 1880 through 2017.






